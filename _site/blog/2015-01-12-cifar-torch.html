
<!DOCTYPE html>

<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>The Super Effectiveness of Convolutional Neural Nets</title>
  <meta name="description" content="My journey to learn how to learn">

  <link rel="canonical" href="/blog/2015-01-12-cifar-torch.html">
  <!-- <link rel="alternate" type="application/rss+xml" title="neale.github.io" href="/feed.xml" /> -->

  <!-- Latest compiled and minified CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
 

	
  <!--Added styles css-->	
  <link rel="stylesheet" href="/css/normalize.css"/>

  <link rel="stylesheet" href="/css/custom.css"/>

   <link rel="stylesheet" href="/css/style.css"/>

    <!--Font awesome-->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

   <!--modernizr-->
   <script src="js/modernizr.js"></script>
	


</head>


  <body>
  <!--[if lt IE 7]>
      <strong>It seems your browser is quite a bit old, to get latest browser go to this link <a href="http://browsehappy.com">BROWSE HAPPY </a> And get the happy face</strong>
  <![endif]-->

  
<!-- Start with the header -->
<section class="header" id="header">



    <a class="tab pi-default pi-big pi-flat" target="_blank" href="https://github.com/"><class=""></></a>

    <!-- Main Head Title -->
    <h2><a href="/">neale.github.io</a></h2>
    




</section>












    <div class="container">


          <!--start of the post title-->
    <section class="single-post-title-main">
        <h2>The Super Effectiveness of Convolutional Neural Nets</h2>
    </section>
<!--End of the post title-->

<!--Start of the section post-->
    <section class="post">
       <p>
          <!-- To -->

<div class="post-img">
<p align="center">  
<img class="img-responsive img-post" src=" /img/synapse.jpeg " />
</p>
</div>

<h1 id="prologue">Prologue</h1>

<p>Neural networks have become so pervasive in the machine learning community that I began to wonder if they were really worth all the hype. There are daily publications on arXiv
and on Hacker News about new deep learning techniques and new architectures. Many of these are grad students applying neural networks to a job that doesn’t need their 
special sauce. But there are two areas in particular where neural nets have provided such a boost in ability, that its not even fair to compare them to conventional 
machine learning models: object recognition and natural language processing. Object recognition in particular exploded the field of deep learning when Alex Krizhevsky 
trounced the competition at ILSVRC of 2012. Alexnet was an 8 layer convolutional neural network that achieved over 20% better top-5 error on imagenet than the next leading entry. 
This is the equivilant of a toddler competing against a slightly senile old man. It may not seem like a lot, but this advancement was unprecedented and lit a fire of 
research in the computer vision community.</p>

<p>For my machine learning class in my undergrad I implemented a CNN in Torch and compared it to standard image recognition techniques like Nearest Neighbor clustering and Kernel SVMs. 
I compared the models on the cifar-10 and MNIST datasets. MNIST is a dataset of 60000 images, each of a handwritten digit 0-9. The images are sized 32x32 binary pixels, for a total of 1024 
dimensions. In terms of images this is extremely low dimensional data and makes for a simple, small model. Cifar-10 however, contains RGB images of 10 classes of objects, shown in 
different scales, translations, and rotations. Cifar images have 3072 dimensions, but there are far more latent features contained that need to be extracted. Recognizing airplaces 
in multiple different positions requires a different approach than being able to differentiate different binary images of digits.</p>

<h2 id="models">Models</h2>

<p>For MNIST here is the code that I used to generate a fast implementation of a feed forward neural network and a Nearest Neighbor classifier in python and scikit-learn. 
I made these models small because I had a hunch that a simple algorithmm would all that would be required to classify the digits correctly.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_data</span><span class="p">():</span>
  <span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_mldata</span><span class="p">(</span><span class="s">'MNIST original'</span><span class="p">)</span>
  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">data</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="n">mnist</span><span class="o">.</span><span class="n">target</span>
  <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">60000</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">60000</span><span class="p">:]</span>
  <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="mi">60000</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">60000</span><span class="p">:]</span>
  <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span>

<span class="k">def</span> <span class="nf">build_clf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">clf_class</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="s">"""build any classifier that implements a fit method with
  given parameters"""</span>

  <span class="n">clf</span> <span class="o">=</span> <span class="n">clf_class</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="n">clf_fit</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">clf_fit</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
  <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
  <span class="n">KNN_hyperparams</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s">'n_neighbors'</span> <span class="p">:</span> <span class="mi">9</span><span class="p">,</span>
      <span class="s">'n_jobs'</span>      <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
      <span class="s">'algorithm'</span>   <span class="p">:</span> <span class="s">'auto'</span><span class="p">,</span>
      <span class="s">'p'</span>           <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s">'leaf_size'</span>   <span class="p">:</span> <span class="mi">10</span>
  <span class="p">}</span>
  <span class="n">MLP_hyperparams</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s">'hidden_layer_sizes'</span> <span class="p">:</span> <span class="p">(</span><span class="mi">512</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span>
      <span class="s">'activation'</span>         <span class="p">:</span> <span class="s">'relu'</span><span class="p">,</span>
      <span class="s">'algorithm'</span>          <span class="p">:</span> <span class="s">'sgd'</span><span class="p">,</span>
      <span class="s">'batch_size'</span>         <span class="p">:</span> <span class="s">'auto'</span><span class="p">,</span>
      <span class="s">'alpha'</span>              <span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
      <span class="s">'max_iter'</span>           <span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
      <span class="s">'verbose'</span>            <span class="p">:</span> <span class="bp">True</span>
  <span class="p">}</span>
  <span class="k">print</span> <span class="s">"building KNN"</span>
  <span class="n">knn</span> <span class="o">=</span> <span class="n">build_clf</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">KNN</span><span class="p">,</span> <span class="o">**</span><span class="n">KNN_hyperparams</span><span class="p">)</span>
  <span class="k">print</span> <span class="s">"KNN Training set score: </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
  <span class="k">print</span> <span class="s">"KNN Test set score: </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>

  <span class="k">print</span> <span class="s">"building MLP"</span>
  <span class="n">mlp</span> <span class="o">=</span> <span class="n">build_clf</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">MLPClassifier</span><span class="p">,</span> <span class="o">**</span><span class="n">MLP_hyperparams</span><span class="p">)</span>
  <span class="k">print</span> <span class="s">"MLP 1 Training set score: </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
  <span class="k">print</span> <span class="s">"MLP 1 Test set score: </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
</code></pre></div></div>

<p>The rest of the code can be found <a href="https://github.com/neale/ConvNet/blob/master/linearClassifier/KNN_MLP.py">here</a> if you want to implement it yourself.
The neural network took 30 minutes to converge, running on a NVIDIA GTX 970. From there it could do a forward and backward pass in 50+ ms to classify an example. 
If all of this is gibberish you should read my <a href="http://neale.github.io">simplified neural network</a> post. Both models preformed better than 95%, which is what is expected of human
participants in an equivilant task.</p>

<p>The Convnets I used were of two different architectures, a small one for MNIST and a deeper network for cifar-10. The MNIST convnet had few weights (60k) and was 
lightly regularized, while the deeper net was a VGG16-style net which was heavily regularized with 16 layers. Here are the presented architectures for both of the convnets</p>

<div class="post-img">
<p align="center">
<img class="img-responsive img-post" src=" /img/conv_architectures.png" width="600" height="1400" />
</p>

</div>

<p>For both architectures I used small convolutional filters to minimize parameter growth in such a deep network
if you want to know more details about the architecture I have a research paper posted <a href="http://github.com/neale/convnet/blob/master/effect-model-complexity.pdf">here</a>
that you should read. The CNN trained for a few hours on MNIST, and for two days on cifar-10 until it finally converged. The results were well worth the wait.</p>

<p>Here is the larger Convnet model that I used to classify cifar-10, written in torch</p>

<div class="language-lua highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kd">local</span> <span class="n">vgg</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="c1">-- building block conv layer function</span>
<span class="c1">-- One conv layer with a ReLU, </span>
<span class="c1">-- Maybe try and optimize with a leaky ReLU to prevent dead neurons </span>

<span class="kd">local</span> <span class="k">function</span> <span class="nf">ConvReLU</span><span class="p">(</span><span class="n">nInputPlane</span><span class="p">,</span> <span class="n">nOutputPlane</span><span class="p">)</span>
  <span class="n">vgg</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">SpatialConvolution</span><span class="p">(</span><span class="n">nInputPlane</span><span class="p">,</span> <span class="n">nOutputPlane</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
  <span class="n">vgg</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">true</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">vgg</span>
<span class="k">end</span>

<span class="c1">-- heavy regularization with a .6 dropout probability</span>

<span class="n">ConvReLU</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">):</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ConvReLU</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">):</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ConvReLU</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">)</span>
<span class="n">vgg</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">):</span><span class="n">ceil</span><span class="p">())</span>
<span class="n">vgg</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">View</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>

<span class="c1">-- terminate the conv network with a fully connected neural network</span>
<span class="c1">-- linear FC units act as a classifier, to consolidate the conv-feature maps into 10 classes</span>
<span class="c1">-- final softmax to generate negative log probabilities for each class</span>

<span class="n">clr</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">clr</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">))</span>
<span class="n">clr</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">))</span>
<span class="n">clr</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">true</span><span class="p">))</span>
<span class="n">clr</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">))</span>
<span class="n">clr</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">clr</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">criterion</span><span class="p">.</span><span class="n">LogSoftmax</span><span class="p">())</span>
</code></pre></div></div>

<p>Here are the model results from the benchmarks I ran:</p>

<h2 id="testing-configuration">Testing Configuration</h2>

<p>Models were trained and tested the same system</p>

<ul>
  <li>
    <p>i7 6700K</p>
  </li>
  <li>
    <p>GTX 970</p>
  </li>
  <li>
    <p>32GB DDR4</p>
  </li>
</ul>

<h2 id="model-benchmarks-top-1">Model Benchmarks (Top 1)</h2>

<div class="post-img">
<img class="img-responsive img-post" src=" /img/conv_stats.png" align="center" width="80%" height="80%" />
</div>

<p>As you can see, the convnet outpreforms every other model by a wide margin. This is because convnets encode features independant of their placement in the image. 
This allows us to train these models end to end without a object detection layer. If the feature is present, the convnet will find it no matter how the feature is translated or rotated.</p>

<p>CNNs are more effective than any other model in terms of classification speed (a single forward and backward pass can be as low as 50ms), and raw accuracy. But CNNs take much more data and much longer to train than other algorithms. 
This tradeoff is further discussed <a href="https://github.com/neale/convnet/blob/master/effect-model-complexity.pdf">in this paper</a></p>

<h3 id="references">References:</h3>

<p>[1] <a href="http://torch.ch/docs/package-docs.html">torch</a></p>

<p>[2] <a href="http://cs231n.github.io/">Andrej karpathy’s CS231n class</a></p>

<p>[3] <a href="https://www.cs.toronto.edu/~kriz/cifar.html">cifar-10</a></p>

<p>[4] <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></p>


       </p>

    </section>

    <!--start of section author-->
    <section class="single-author">
        <div class="post-details">
            
            <span> Done At: Jul 14,2016</span>
            <div class="categories">
                <em>Categories:</em>
                <ul>
                
                    <li><a>NN</a></li>
                    
                   
                </ul>
            </div>

          

        </div>
    </section>
<!--End of section author-->
	
  <div class="col-sm-offset-2 col-sm-10 col-md-offset-2 col-md-8">
	    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'EnRatz'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    
  </div>
	

   
  </div>

</div>
<hr/>



</section>




    <section class="footer ">

    <div class="row">

        <div class="col-sm-offset-3 col-md-offset-3 col-md-6 text-center">
            


            

            


            
        </div>

    </div>
 
      <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'EnRatz'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
    </script>


</section>


    </div>
    <!-- Scripts -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="assets/js/jquery.js"><\/script>')</script>

<!-- Add custom scripts here -->
<!-- Bootstrap js -->
<script type="text/javascript" src="js/bootstrap.min.js"></script>

<!-- Parallax js -->
<script type="text/javascript" src="jquery.localscroll-1.2.7-min.js"></script>
<script type="text/javascript" src="jquery.parallax-1.1.3.js"></script>
<script type="text/javascript" src="jquery.scrollTo-1.4.2-min.js"></script>
<script src="js/snippet.js"></script>
<!-- /end of parallax js -->



<!-- Add your google analytics here -->
<!-- Change the XXXXXXX section in your site id -->
<script>
    (function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=
            function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;
        e=o.createElement(i);r=o.getElementsByTagName(i)[0];
        e.src='//www.google-analytics.com/analytics.js';
        r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));
    ga('create','UA-XXXXX-X');ga('send','pageview');
</script>

	



  </body>

</html>
