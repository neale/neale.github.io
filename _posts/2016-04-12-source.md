---
layout: post
title:  "Generating code with character level RNNs "
date:   2016-01-12 23:25:05
categories: NN
image: true
---



<!--To start off this **Blog** I thought I would give a history of where Ive been on my short ourney so for, starting with my first encounter with a neural net. A year or so ago I came across an npm package called Synaptic which gives some functions for defining the behavior of artificial neurons.-->

Well I said I was going to source code with my character RNN and last weekend I did just that. I grabbed the largest open source programs I could find. 
Obviously I took the linux kernel, and then I thought it would be interesting to see what a neural network thought of itself. So I concatonated the Torch source 
that's on Github and sent it through the LSTM. The last thing I did was take all of my code, every last piece of it that's on Github and tried to see what an RNN 
thinks of my code. Mostly I was sure that the Linux and Torch sources were going to give much cleaner representations of code than my own source will. 

## Linux Source Code

Without further delay, I downloaded the Linux source from [Github](https://github.com/torvalds/linux) as a frustratingly large repository of 1.5GB

In order to cat all the files into one disgustingly long file I ran a simple bash line 


> `find linux/ -name '*c' -exec cat {} \; > ../linux.txt`


This file was a lot larger than the C.S. Lewis corpus, at 541MB and needed 50 days to train with a 6 layer LSTM. I didn't want to wait that long so I cut the file down to 50MB and trained it from there. Here is some of the sampled code it generated. 
This time I'm going to cherry pick the results because I think that's more interesting. We already know these models aren't perfect. 


```c
struct seq_file omap2_current_clkdm = {
        .name = "root[-32",
        .traps = vcpu->arch.entry,
        .gpio_cap = ia64_execution_setup,
        .ll = have_apply_vddump,
        .config_r_set = omap3_ll_core_red.fn,
};

static void __omap1_code_init(void)
{
        int rt;

        pci_dir_dt_map_partte(val);
}

static char *pxa27x_pxa_reset_interrupts[] = {
        ARMV7_PERFCTR_TC_INTLM,
        MFP_FAULT(EXP_OFFSET, IS_CALL_AT_P, 0),
        IO_ADDRESS(ETRAX_PM_CONTROL_0),
        SMART_DAT(0x00),
        SMART_DAT(0x00),
        SMART_CMD(0x00),
        SMART_CMD(1130),
        CLK(VAL1_9, 5, 49, 3, 1, 1),
};

```

> There's a whole lot of learning take place, from just characters the LSTM has learned to generate code that with a little work, could compile. 
> This code could probably fool most undergraduate TAs into thinking the student did some work. Althrough if the student was generating their code with an LSTM, 
> they probably deserve a decent grade. 


```c
static struct platform_driver *pmu_config[] = {
        /* MIPS of support */
        char * power_map_arch = {
                NUM_UHAX_DEVID_BASE_END };
        __stackpoint_idtop.mask = 0;
        /* Wree test counter uses for range to configure RESH, input */
        if (edit_tables[1] == 4)
                cpu_none = jab_boot();
        qeat_info->ia32 = 0;
        if (!__pstate_thread_flag (&(frame->dma_ptr) == 4)) {
                pr_info("%s: */
                pe_current_node = 0;
        }
        max = new_cache_page[ncriss_reading.cpu];
        if (err < 16) {
                switch (ch) {
                        case 1:
                        break;
                }
        }
        __flush_icache_range(lan, highol.etbys);
        __raw_writel(1, regs->lan, current->internal);
        spin_lock_irqsave(&cpu);
        xcmp_init(&bv->setups);
}

```

> I saved the best for last, this was the best piece of code that the network generated in my 5000 character sample. In this one function, it uses `case`, 
single line if statements, `struct.` and `&struct->`, and functions that take none to many arguments. 

C is a very structured lanuage, so there were larger, more obvoius features for the RNN to pick out which I think helped its training. 
Higher level languages would have more trouble since the interpreter does so much of the heavy lifting. That sounds like a challenge, so lets not just tackle another language. 
We're going to generate code from the same RNN, trained on a deep learning framework.

## Torch Framework Generation


I was really excited for this, I wanted to see how a neural network would write scientific code. Torch is a smaller dataset than the Linux source, so I added the cudnn and rnn library sources.
I'm really considering adding in more Torch code from other repositories just to boster the dataset. But I can't control how valid someone else's Torch code is so that seems more likely to contaminate the dataset then help it. I still might do it. 

The methodology here is much the same, I downloaded the source from [Github](https://github.com/torch/torch7) and catted the whole thing with the above command.
The resulting text file was ~2MB so I figured it was good to go. Here's some of the generated source, this is how a neural net would build itself. 

```lua 

function LSTM:__init(value)
   end
   assert(step >= 1, "set '] then
      self:recursiveCopy(self.outputSize, t1)
   end

   -- get the it  convertis sequencen the input to return and (targets through forward for layers
   
   self._sequence[self.step-1] = torch.dim() do
      -- Uoth initialModule
      self.step = 1
      assert(torch.type(checkSums.localSumh == next_c)) 
      self._gradOutput = self.initialModule or torch.LongStorage(self.inputSize, output:size(2))
      if table.insert(self.modules[1] rho <= 1) and nStep >= 'both' then
         self.bias:=4:clone(), self.bwdSeq)
      return self
end

```

> wow, the LSTM is writing an LSTM. Is that cannibalism, or asexual reproduction?


It even got the commments right, but they're a little funky since the network doesn't have any language reference, just source code. 
So all it knows how to talk about is networks, which probably works. 


I was particularly impressed by this bit, it closes parentheses well and it even got the dot operator right. 

```lua

assert(torch.type(checkSums.localSumh == next_c)) 
self._gradOutput = self.initialModule or torch.LongStorage(self.inputSize, output:size(2))
if table.insert(self.modules[1] rho <= 1) and nStep >= 'both' then

```

> This is totally reasonbable lua code that only doesn't work if you look really close. This really speaks to the quality of code that makes up Torch.
> The generated text would be way more convoluted if the source wasn't consistant. 

```lua

function matInput:clone()
   self.zeroTensor = self.recurrentModule
   self.output = gradOutput:clone()
   self.gradOutput = nil
   for step=nStep,1,10 do
      seq2.input = self.step * 1
      self._gradInputs = outputs[1]:sub() * sequence:size(1) 
      self.step = nil
      output:transpose(1,1):seq(self.outputsize)
      self.output:size(1) = self.gradOutput:clone()
end

```



Next I just need to train the RNN on my own code, this is going to be the most humbling experience of my programming life. 


