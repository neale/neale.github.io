---
layout: post
title:  "Generating code with character level RNNs "
date:   2016-01-12 23:25:05
categories: NN
image: true
---



<!--To start off this **Blog** I thought I would give a history of where Ive been on my short ourney so for, starting with my first encounter with a neural net. A year or so ago I came across an npm package called Synaptic which gives some functions for defining the behavior of artificial neurons.-->

Well I said I was going to source code with my character RNN and last weekend I did just that. I grabbed the largest open source programs I could find. 
Obviously I took the linux kernel, and then I thought it would be interesting to see what a neural network thought of itself. So I concatonated the Torch source 
that's on Github and sent it through the LSTM. The last thing I did was take all of my code, every last piece of it that's on Github and tried to see what an RNN 
thinks of my code. Mostly I was sure that the Linux and Torch sources were going to give much cleaner representations of code than my own source will. 

## Linux Source Code

Without further delay, I downloaded the Linux source from [Github](https://github.com/torvalds/linux) as a frustratingly large repository of 1.5GB

In order to cat all the files into one disgustingly long file I ran `find linux/ -name '*' -exec cat {} \; > linux.txt`

This file was a lot larger than the C.S. Lewis corpus, and needed a correspondingly larger amount to train, but here is some of the sampled code. 
This time I'm going to cherry pick the results because I think that's more interesting. We already know these models aren't perfect. 


```c
-
-
-
```

> Should I even turn on highlighting for this. Linus is probably throwing a fit about deflowering C or something. 

### So I don't know what happened to this page, but I'm retraining for all these examples right now. Just sit tight for a couple days

## Torch Framework Generation

I was really excited for this, its a smaller dataset than the Linux source. I'm really considering adding in more Torch code from other repositories just to boster the dataset. 
But I can't control how valid someone else's Torch code is so that seems more likely to contaminate the dataset then help it. I still might do it. 

The methodology here is much the same, I downloaded the source from [Github](https://github.com/torch/torch7) and catted the whole thing with the above command.
The resulting text file was ~200MB so I figured it was good to go. 


### Also lost I dont know what happened 




