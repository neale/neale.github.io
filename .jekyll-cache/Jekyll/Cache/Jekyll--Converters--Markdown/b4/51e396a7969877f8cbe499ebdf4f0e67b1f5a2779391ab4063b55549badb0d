I"ù<p>Iâ€™m Neale Ratzlaff, ðŸŒ² ðŸŒ² a Deep Learning and Computer Vision researcher, working Bayesian deep learning, with applications to computer vision and deep reinforcement learning</p>

<p>Iâ€™m a PhD candidate studying with Dr. <a href="https://web.engr.oregonstate.edu/~lif/">Fuxin Li</a> at Oregon State University.
Iâ€™m broadly interested in implicit variational inference, generative models, uncertainty, and information geometry. Itâ€™s important to create AI agents which we can trust, meaning I spend a lot of time thinking about alignment and paperclips.</p>

<p>Currently Iâ€™m interested in learning distributions over functions, and using them to improve methods in computer vision and reinforcement learning. By leveraging some recent advances in particle vairational inference, we can learn these intractable distributions even for complex neural networks. The resulting distributions have numerous benefits over single models, and even bootstrapped ensembles.</p>

<p>Iâ€™ve worked at <a href="https://horizon.ai/">Horizon Robotics</a>, <a href="https://vimeo.com/170280447">Intel</a>, and <a href="https://www.tek.com/">Tektronix</a></p>
<div style="text-align:center"><img src="/images/horizon_logo.png" /> <img src="/images/intel_logo.png" /> <img src="/images/tek_logo.png" /> </div>

<h1 id="papers">Papers</h1>

<h3 id="generative-particle-variational-inference-via-estimation-of-functional-gradients"><a href="https://arxiv.org/abs/2103.01291">Generative Particle Variational Inference via Estimation of Functional Gradients</a></h3>

<p><strong>Ratzlaff</strong><sup>â˜¨</sup>, Bai<sup>â˜¨</sup>, Fuxin, Xu. (Under Review) 2021,</p>

<p>(â˜¨): Equal Contribution</p>

<p>Code: coming very soon</p>

<p>We introduce a new method for Bayesian deep learning: GPVI, that fuses the flexibility of particle-based variational methods, with the efficiency of generative samplers. We construct a neural sampler that is trained with the functional gradient of the KL-divergence between the empirical sampling distribution and the target distribution. We show that GPVI accurately models the posterior distribution when applied to density estimation and Bayesian neural networks. This work also features a new method for estimating the inverse of the input-output jacobian without invertibility restrictions.</p>

<div style="text-align:center"><img src="/images/2class-sin.png" /></div>

<hr />

<h3 id="avoiding-side-effects-in-complex-environments"><a href="https://128.84.21.199/abs/2006.06547">Avoiding Side-Effects in Complex Environments.</a></h3>

<p>Turner<sup>â˜¨</sup>, <strong>Ratzlaff</strong><sup>â˜¨</sup>, Tadepalli. (<strong>NeurIPS</strong>) 2020, <strong>Spotlight talk</strong></p>

<p>(â˜¨): Equal Contribution</p>

<p>Code: <a href="https://github.com/neale/avoiding-side-effects">Github Repo</a></p>

<p>We introduce reinforcement learning agents that can accomplish goals without incurring side effects. Standard RL agents collect reward at any cost, often unsustainably ruining the environment around them. The attainable utility penalty (AUP) penalizes agents for acting in a way that decreases in their ability to achieve unknown future goals. We extend AUP to the deep RL case, and show that our AUP agents can act in difficult environments with stochastic dynamics, without incurring side effects.</p>

<div style="text-align:center"><img src="/images/aup_paper.png" /></div>

<hr />

<h3 id="implicit-generative-modeling-for-efficient-exploration"><a href="https://arxiv.org/abs/1911.08017">Implicit Generative Modeling for Efficient Exploration.</a></h3>

<p><strong>Ratzlaff</strong>, Bai, Fuxin, Xu. (<strong>ICML</strong>) 2020</p>

<p>We model uncertainty estimation as an intrinsic reward for efficient exploration. We introduce an implicit generative modeling approach to estimate a Bayesian uncertainty of the agentâ€™s belief of theenvironment dynamics.  We approximate the posterior through multiple draws from our generative model. The variance of the dynamic modelsâ€™ output is used as an intrinsic reward for exploration. We design a training algorithm for our generative model based on amortized Stein Variational Gradient Descent, to ensure the parameter distribution is a nontrivial approximation to the true posterior.</p>

<div style="text-align:center"><img src="/images/RLpaper_hypergan.png" /></div>

<hr />

<h3 id="hypergan-a-generative-model-for-diverse-performant-neural-networks"><a href="http://proceedings.mlr.press/v97/ratzlaff19a/ratzlaff19a.pdf">HyperGAN: A Generative Model for Diverse Performant Neural Networks.</a></h3>

<p><strong>Ratzlaff</strong>, Fuxin. (<strong>ICML</strong>) 2019</p>

<p>Code: <a href="https://github.com/neale/HyperGAN">HyperGAN Github repo</a></p>

<p>Talk: ICML Oral <a href="https://slideslive.com/38917398/general-ml">Slideshare</a></p>

<p>We learn an implicit ensemble using a neural generating network. Trained by maximum likelihood, the generator learns to sample from the posterior of model parameters which fit the data. 
The generated model parameters achieve high accuracy, yet are distinct with different predictive distributions. 
We enforce diversity by regularizing the intermediate representations to be well-distributed, while not harming the flexibility of the output distribution.</p>

<div style="text-align:center"><img src="/images/hypergan.png" /></div>

<hr />

<h3 id="unifying-bilateral-filtering-and-adversarial-training-for-robust-neural-networks"><a href="https://arxiv.org/abs/1804.01635">Unifying Bilateral Filtering and Adversarial Training for Robust Neural Networks.</a></h3>

<p><strong>Ratzlaff</strong>, Fuxin. (<em>arxiv</em> preprint) 2018</p>

<p>Code: <a href="https://github.com/neale/adversarial-toolbox">Github repo</a></p>

<p>We use an adaptive bilateral filter to smooth the purturbations left by adversarial attacks. We view our method as a piecewise projection of the high frequency perturbations, back to the natural image manifold. Our method is simple, effective, and practical, unlike many other projection defenses</p>

<p><img src="/images/BFNet.png" alt="BFNet" /></p>

<hr />

<h1 id="theses">Theses</h1>

<h3 id="methods-for-detection-and-recovery-of-out-of-distribution-examples-ms-degree-computer-science-oregon-state-university-2018"><a href="https://ir.library.oregonstate.edu/concern/graduate_thesis_or_dissertations/mw22vb88d">Methods for Detection and Recovery of Out-of-Distribution Examples.</a> M.S. Degree Computer Science. Oregon State University (2018)</h3>

<div style="text-align:center"><img src="/images/class.png" /> <img src="/images/density.png" /> </div>

<hr />

<h1 id="code">Code</h1>

<p>I maintain and work on various other projects, all deep learning related. Pretty much all of them are in PyTorch.</p>

<ul>
  <li><a href="https://github.com/neale/adversarial-autoencoder">Adversarial Autoencoders</a></li>
  <li><a href="https://github.com/neale/Improved-WGAN">Improved Wassersteion GAN</a></li>
  <li><a href="https://github.com/neale/CPPN">Compositional Pattern Producing Networks</a></li>
  <li><a href="https://github.com/neale/PySMTDNN">Satisfiable Neural Networks (PySMT-DNN)</a></li>
</ul>

<hr />

<h1 id="generative-art">Generative Art</h1>

<p>Inspired by <a href="http://blog.otoro.net/">Hardmaru</a>, I build evolutionary creative machines. There is gallery of examples <a href="./gen_art.html">here</a></p>

:ET